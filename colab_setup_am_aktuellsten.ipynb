{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHV4FlFHAluR"
      },
      "source": [
        "# UCF-Crime Anomaly Detection - Colab Setup\n",
        "\n",
        "Setup notebook for running MIL Ranking Loss re-implementation on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBVYUezmAluU"
      },
      "source": [
        "## 1. Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JOBpotWRAluV",
        "outputId": "6a4cb675-c419-481e-e537-b2784c092656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "\n",
            "PyTorch CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "# Verify PyTorch can use GPU\n",
        "import torch\n",
        "print(f\"\\nPyTorch CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5DgE0hZAluX"
      },
      "source": [
        "## 2. Mount Google Drive\n",
        "\n",
        "**Prerequisites:**\n",
        "1. Upload features.zip and annotations.zip to Google Drive\n",
        "2. Google Drive structure:\n",
        "```\n",
        "MyDrive/\n",
        "└── Colab Notebooks/\n",
        "    └── data_distribution/\n",
        "        ├── features.zip\n",
        "        └── annotations.zip\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zpbnWpoOAluY",
        "outputId": "1f1f6e6f-a9cc-4172-effc-a5ddc8bbefbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixh9aKZpAluY"
      },
      "source": [
        "## 3. Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cN86klE3AluZ",
        "outputId": "ff5c5034-f829-429a-be8e-116e6ab81c9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MILRankingLoss_Sultani2018_ReImplementation'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 39 (delta 7), reused 37 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (39/39), 245.14 KiB | 7.66 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/MILRankingLoss_Sultani2018_ReImplementation\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/KwonPodo/MILRankingLoss_Sultani2018_ReImplementation.git\n",
        "%cd MILRankingLoss_Sultani2018_ReImplementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYTx5rA8AluZ"
      },
      "source": [
        "## 4. Install Packages\n",
        "\n",
        "**Note:** Using `requirements-colab.txt` to avoid package conflicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dsEzNu4yAluZ",
        "outputId": "5e451636-60db-4d9d-bf66-48f33f74c88d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.9.0+cu126\n",
            "NumPy: 2.0.2\n"
          ]
        }
      ],
      "source": [
        "# Install minimal packages for Colab (avoid conflicts)\n",
        "!pip install -r requirements-colab.txt -q\n",
        "\n",
        "# Check installed package versions\n",
        "import torch\n",
        "import numpy as np\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"NumPy: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR85hP2ZAlua"
      },
      "source": [
        "## 5. Extract Data\n",
        "\n",
        "Extract features from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljx0YhMdAlua",
        "outputId": "8d059fe4-0f4b-4de4-a73b-2f76199903da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MILRankingLoss_Sultani2018_ReImplementation\n",
            "/content/MILRankingLoss_Sultani2018_ReImplementation\n",
            "Features extracted\n",
            "total 4.0K\n",
            "drwxr-xr-x 17 root root 4.0K Oct 31 17:28 features\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Verify working directory\n",
        "%cd /content/MILRankingLoss_Sultani2018_ReImplementation\n",
        "!pwd\n",
        "\n",
        "# Create data directory\n",
        "!mkdir -p data\n",
        "\n",
        "# Google Drive path\n",
        "DRIVE_DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/data_distribution'\n",
        "\n",
        "# Extract features\n",
        "!cp \"{DRIVE_DATA_PATH}/features.zip\" data/\n",
        "!unzip -q data/features.zip -d data/\n",
        "!rm data/features.zip\n",
        "\n",
        "print(\"Features extracted\")\n",
        "!ls -lh data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xBY_cYsAlub"
      },
      "source": [
        "## 6. Extract Annotations\n",
        "\n",
        "Extract annotation files from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kUBBCdNWAlub",
        "outputId": "4ef6a101-f2f6-4c4b-d0a0-5110e5200cea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations extracted\n",
            "total 100K\n",
            "-rwxr-xr-x 1 root root 16K Jan  3  2023 Temporal_Anomaly_Annotation_for_Testing_Videos.txt\n",
            "-rwxr-xr-x 1 root root 13K Oct 31 17:28 test_set.txt\n",
            "-rwxr-xr-x 1 root root 66K Oct 31 17:28 train_set.txt\n"
          ]
        }
      ],
      "source": [
        "# Extract annotations from Google Drive\n",
        "!cp \"{DRIVE_DATA_PATH}/annotations.zip\" data/\n",
        "!unzip -q data/annotations.zip -d data/\n",
        "!rm data/annotations.zip\n",
        "\n",
        "print(\"Annotations extracted\")\n",
        "!ls -lh data/annotations/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpfq0vBFAlub"
      },
      "source": [
        "## 7. Verify Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LBCiYbInAlub",
        "outputId": "01e418b4-2282-41bc-c987-c1086cefef08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MILRankingLoss_Sultani2018_ReImplementation\n",
            "Abuse\tAssault    Fighting\t  Shooting     Testing_Normal_Videos_Anomaly\n",
            "Arrest\tBurglary   RoadAccidents  Shoplifting  Training_Normal_Videos_Anomaly\n",
            "Arson\tExplosion  Robbery\t  Stealing     Vandalism\n",
            "Train samples:\n",
            "1610 data/annotations/train_set.txt\n",
            "Test samples:\n",
            "290 data/annotations/test_set.txt\n"
          ]
        }
      ],
      "source": [
        "# Verify working directory\n",
        "%cd /content/MILRankingLoss_Sultani2018_ReImplementation\n",
        "\n",
        "# Check feature categories\n",
        "!ls data/features/\n",
        "\n",
        "# Check sample counts\n",
        "!echo \"Train samples:\"\n",
        "!wc -l data/annotations/train_set.txt\n",
        "!echo \"Test samples:\"\n",
        "!wc -l data/annotations/test_set.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR-jvSNVAlub"
      },
      "source": [
        "## 8. Test Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S1p7Y_e3Aluc",
        "outputId": "35edb3bd-6f1e-426d-860e-cfc766beb453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MILRankingLoss_Sultani2018_ReImplementation\n",
            "Total samples in dataset: 1610\n",
            "Positive samples: 810\n",
            "Negative samples: 800\n",
            "\n",
            "First batch:\n",
            "\n",
            "Positive bags: torch.Size([30, 32, 4096])\n",
            "\n",
            "Negative bags: torch.Size([30, 32, 4096])\n",
            "Batch 0: pos=30, neg=30\n",
            "Batch 1: pos=30, neg=30\n",
            "Batch 2: pos=30, neg=30\n",
            "Batch 3: pos=30, neg=30\n"
          ]
        }
      ],
      "source": [
        "%cd /content/MILRankingLoss_Sultani2018_ReImplementation\n",
        "!PYTHONPATH=/content/MILRankingLoss_Sultani2018_ReImplementation:$PYTHONPATH python scripts/test_dataset.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_hR5ts6Aluc"
      },
      "source": [
        "## 9. Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lI23epz0Aluc",
        "outputId": "4f72d880-8fad-4608-9258-9e55683abee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MILRankingLoss_Sultani2018_ReImplementation\n",
            "Model architecture:\n",
            "AnomalyDetector(\n",
            "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.6, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Total parameters: 2,114,113\n",
            "\n",
            "Positive scores shape: torch.Size([30, 32])\n",
            "Negative scores shape: torch.Size([30, 32])\n",
            "Score range: [0.4856, 0.5983]\n",
            "\n",
            "Total loss: 1.0416\n",
            "  Ranking loss: 1.0000\n",
            "  Smoothness loss: 0.5422\n",
            "  Sparsity loss: 519.6133\n",
            "\n",
            "Training mode loss: 1.0364\n"
          ]
        }
      ],
      "source": [
        "%cd /content/MILRankingLoss_Sultani2018_ReImplementation\n",
        "!PYTHONPATH=/content/MILRankingLoss_Sultani2018_ReImplementation:$PYTHONPATH python scripts/test_model.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB2lSCi8Aluc"
      },
      "source": [
        "## 10. Start Training\n",
        "\n",
        "### Option 1: Train without WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBL-cRVuAluc",
        "outputId": "2c798dab-e1e6-4564-d9e3-4a3027e37825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MILRankingLoss_Sultani2018_ReImplementation\n",
            "Loaded config from configs/default.yaml\n",
            "Using device: cpu\n",
            "Train dataset: 1610 videos\n",
            "Positive samples: 810\n",
            "Negative samples: 800\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Total batches per epoch: 26\n",
            "Model parameters: 2,114,113\n",
            "Optimizer: adam\n",
            "\n",
            "Starting training for 100 epochs...\n",
            "Epoch 1:   0% 0/26 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1: 100% 26/26 [01:29<00:00,  3.44s/it, loss=1.0356, rank=0.9996]\n",
            "Epoch 1/100\n",
            "  Loss: 1.0362\n",
            "  Ranking: 0.9998\n",
            "  Smoothness: 0.0377\n",
            "  Sparsity: 454.4468\n",
            "  Saved checkpoint: checkpoints/epoch_1.pth\n",
            "  New best model: checkpoints/best_model.pth\n",
            "Epoch 2: 100% 26/26 [01:32<00:00,  3.56s/it, loss=1.0352, rank=0.9998]\n",
            "Epoch 2/100\n",
            "  Loss: 1.0356\n",
            "  Ranking: 0.9998\n",
            "  Smoothness: 0.0530\n",
            "  Sparsity: 446.9604\n",
            "  Saved checkpoint: checkpoints/epoch_2.pth\n",
            "  New best model: checkpoints/best_model.pth\n",
            "Epoch 3:  77% 20/26 [01:22<00:18,  3.06s/it, loss=1.0351, rank=1.0000]"
          ]
        }
      ],
      "source": [
        "%cd /content/MILRankingLoss_Sultani2018_ReImplementation\n",
        "!PYTHONPATH=/content/MILRankingLoss_Sultani2018_ReImplementation:$PYTHONPATH python train.py --config configs/default.yaml --no-wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlLkPODfAlud"
      },
      "source": [
        "## 11. Evaluate\n",
        "\n",
        "Evaluate trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5psewryxAlud"
      },
      "outputs": [],
      "source": [
        "%cd /content/MILRankingLoss_Sultani2018_ReImplementation\n",
        "!PYTHONPATH=/content/MILRankingLoss_Sultani2018_ReImplementation:$PYTHONPATH python evaluate.py \\\n",
        "    --config configs/default.yaml \\\n",
        "    --checkpoint checkpoints/best_model.pth \\\n",
        "    --temporal-annotation data/annotations/Temporal_Anomaly_Annotation_for_Testing_Videos.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBlMw-OWAlud"
      },
      "source": [
        "## 12. View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4AjWJnOAlud"
      },
      "outputs": [],
      "source": [
        "%cd /content/MILRankingLoss_Sultani2018_ReImplementation\n",
        "\n",
        "# Display ROC curve\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "if os.path.exists('results/roc_curve.png'):\n",
        "    display(Image('results/roc_curve.png'))\n",
        "\n",
        "\n",
        "if os.path.exists('results/pr_curve.png'):\n",
        "    display(Image('results/pr_curve.png'))\n",
        "\n",
        "# Print evaluation results\n",
        "if os.path.exists('results/evaluation_summary.txt'):\n",
        "    !cat results/evaluation_summary.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSQc8YOYAlud"
      },
      "source": [
        "## 13. (Optional) Save Results to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqspDVTcAlud"
      },
      "outputs": [],
      "source": [
        "%cd /content/MILRankingLoss_Sultani2018_ReImplementation\n",
        "\n",
        "# Backup checkpoints and results to Drive\n",
        "DRIVE_DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/data_distribution'\n",
        "!mkdir -p \"{DRIVE_DATA_PATH}/results\"\n",
        "!cp -r checkpoints \"{DRIVE_DATA_PATH}/\"\n",
        "!cp -r results \"{DRIVE_DATA_PATH}/\"\n",
        "\n",
        "print(\"Results saved to Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. LeakyReLU Activation Function:\n",
        "\n",
        "Before: The original model used the ReLU activation function.\n",
        "\n",
        "After: I replaced ReLU with LeakyReLU. This modification allows a small, non-zero gradient when the input is negative (by setting a small slope, negative_slope=0.01). This is beneficial because, with ReLU, some neurons can \"die\" during training (i.e., they stop updating because they always output 0 for negative inputs). LeakyReLU mitigates this problem by allowing small negative values to propagate.\n",
        "\n",
        "Why: LeakyReLU helps the model learn more efficiently, especially in deep networks where dead neurons can be a problem, improving the overall performance and training stability.\n",
        "\n",
        "2. Dropout Regularization:\n",
        "\n",
        "Before: The original model didn't have dropout regularization, which can lead to overfitting, especially with complex models and limited data.\n",
        "\n",
        "After: I added Dropout with a rate of 0.5 (50% chance of dropping a neuron during training).\n",
        "\n",
        "Why: Dropout helps prevent overfitting by randomly setting a fraction of input units to zero during each forward pass. This encourages the model to not rely too heavily on any single neuron, thus improving generalization to unseen data.\n",
        "\n",
        "3. Batch Normalization:\n",
        "\n",
        "Before: The original model didn't use Batch Normalization.\n",
        "\n",
        "After: I added Batch Normalization after each fully connected layer (FC1 and FC2). This normalizes the output of each layer to have zero mean and unit variance, which stabilizes and speeds up training.\n",
        "\n",
        "Why: Batch Normalization helps the model learn faster by reducing internal covariate shift, which can lead to better performance, especially in deeper networks.\n",
        "\n",
        "4. Network Architecture Changes:\n",
        "\n",
        "Before: The original model had a simpler architecture with just two fully connected layers: 4096 -> 512 and 512 -> 1.\n",
        "\n",
        "After: I added a third fully connected layer with 512 -> 64 neurons. This gives the model an additional layer of abstraction, which could help it learn more complex patterns.\n",
        "\n",
        "Why: Increasing the depth of the network allows the model to learn more complex representations of the data. With the additional layer, the network can model finer-grained relationships between input features, which should improve its ability to detect anomalies.\n",
        "\n",
        "5. Sigmoid Activation:\n",
        "\n",
        "Before: The original model used a Sigmoid function at the output layer, which is still maintained in the new model.\n",
        "\n",
        "Why: The Sigmoid activation is useful for binary classification tasks (0 or 1), where we want the output to represent the probability of an anomaly. Since this is an anomaly detection task, the Sigmoid activation ensures that the model outputs a value between 0 and 1, representing the likelihood of each segment being an anomaly."
      ],
      "metadata": {
        "id": "ulaaPcHnF-0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class ImprovedAnomalyDetector(nn.Module):\n",
        "    \"\"\"\n",
        "    Improved anomaly detection model with LSTM layers for temporal dependencies,\n",
        "    dropout, batch normalization, and LeakyReLU activation.\n",
        "\n",
        "    Architecture:\n",
        "    - LSTM: Input (4096) -> Hidden (256) -> Output (LSTM output)\n",
        "    - FC1: LSTM output -> 512 (LeakyReLU + BatchNorm + Dropout)\n",
        "    - FC2: 512 -> 64 (LeakyReLU + BatchNorm + Dropout)\n",
        "    - FC3: 64 -> 1 (Sigmoid)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=4096, lstm_hidden_size=256, dropout=0.5, lstm_num_layers=2):\n",
        "        super(ImprovedAnomalyDetector, self).__init__()\n",
        "\n",
        "        # LSTM Layer for temporal sequence learning\n",
        "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=lstm_hidden_size,\n",
        "                            num_layers=lstm_num_layers, batch_first=True)\n",
        "\n",
        "        # Fully Connected Layers after LSTM\n",
        "        self.fc1 = nn.Linear(lstm_hidden_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "        # Batch Normalization (optional)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "\n",
        "        # Dropout and activation functions\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (batch_size, num_segments, feature_dim)\n",
        "               e.g., (30, 32, 4096)\n",
        "\n",
        "        Returns:\n",
        "            scores: (batch_size, num_segments)\n",
        "                    Anomaly score for each segment (0~1)\n",
        "        \"\"\"\n",
        "        batch_size, num_segments, feature_dim = x.shape\n",
        "\n",
        "        # LSTM for temporal modeling (use the LSTM output from the last time step)\n",
        "        lstm_out, (hn, cn) = self.lstm(x)  # lstm_out has shape (batch_size, num_segments, lstm_hidden_size)\n",
        "\n",
        "        # Option 1: Use only the last hidden state\n",
        "        x = lstm_out[:, -1, :]  # (batch_size, lstm_hidden_size)\n",
        "\n",
        "        # Fully connected layers with BatchNorm, LeakyReLU, and Dropout\n",
        "        x = self.fc1(x)           # (batch_size, 512)\n",
        "        x = self.bn1(x)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)           # (batch_size, 64)\n",
        "        x = self.bn2(x)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc3(x)           # (batch_size, 1)\n",
        "        x = self.sigmoid(x)       # Final anomaly score\n",
        "\n",
        "        return x  # Anomaly score for the entire sequence (0~1)\n",
        "\n"
      ],
      "metadata": {
        "id": "htIOSVvZEtzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Regularization of Smoothness and Sparsity with Alpha:\n",
        "\n",
        "Before: In the original MILRankingLoss class, the smoothness and sparsity constraints were used directly in the loss function. The weights for these constraints, λ1 (smoothness) and λ2 (sparsity), were defined, but there was no control over how much these two components influenced the total loss.\n",
        "\n",
        "After: I added a new parameter, alpha, which scales the contributions of the smoothness and sparsity terms. This allows us to have more fine-grained control over how much these constraints should affect the final loss.\n",
        "\n",
        "Why: The regularization factor (alpha) allows you to balance the importance of sparsity and smoothness in the overall model. This flexibility can be useful for optimizing the model's performance when you want to adjust how much these terms contribute to the loss function.\n",
        "\n",
        "2. Addition of alpha for Sparsity and Smoothness:\n",
        "\n",
        "Before: The original loss function only included λ1 and λ2 for smoothness and sparsity, respectively, but they were weighted equally in the final loss.\n",
        "\n",
        "After: The total loss is now modified by adding alpha times the sum of the smoothness loss and sparsity loss. This makes it possible to scale the contribution of these terms separately.\n",
        "\n",
        "Why: The alpha factor provides a regularization mechanism that can tune how much influence the smoothness and sparsity have on the final loss. This is helpful because the effects of smoothness and sparsity can vary depending on the data, so alpha allows for easier tuning of the model's behavior."
      ],
      "metadata": {
        "id": "d6KrmX8yFs4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ImprovedMILRankingLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Multiple Instance Learning Ranking Loss with sparsity, smoothness, and L2 regularization constraints.\n",
        "\n",
        "    Loss formula:\n",
        "    loss = hinge_loss + λ1 * smoothness + λ2 * sparsity + λ3 * L2_regularization\n",
        "\n",
        "    where:\n",
        "    - hinge_loss = max(0, 1 - max(pos_scores) + max(neg_scores))\n",
        "    - smoothness = sum of squared differences between adjacent segments\n",
        "    - sparsity = sum of all positive bag scores\n",
        "    - L2_regularization = weight decay on model weights\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lambda1=0.00008, lambda2=0.00008, lambda3=0.0001, alpha=1.0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            lambda1: weight for temporal smoothness constraint\n",
        "            lambda2: weight for sparsity constraint\n",
        "            lambda3: weight for L2 regularization (model weights)\n",
        "            alpha: factor to control how much sparsity and smoothness contribute to the final loss\n",
        "        \"\"\"\n",
        "        super(ImprovedMILRankingLoss, self).__init__()\n",
        "        self.lambda1 = lambda1\n",
        "        self.lambda2 = lambda2\n",
        "        self.lambda3 = lambda3  # L2 regularization weight\n",
        "        self.alpha = alpha  # Regularization factor for sparsity and smoothness terms\n",
        "\n",
        "    def forward(self, pos_scores, neg_scores, model=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pos_scores: (batch_pos, num_segments) - scores for positive bags\n",
        "            neg_scores: (batch_neg, num_segments) - scores for negative bags\n",
        "            model: (optional) The model from which to calculate L2 regularization loss\n",
        "\n",
        "        Returns:\n",
        "            total_loss: scalar tensor\n",
        "            loss_dict: dictionary with individual loss components for logging\n",
        "        \"\"\"\n",
        "        # MIL ranking loss: max score of positive bag should be higher than negative\n",
        "        pos_max = torch.max(pos_scores, dim=1)[0]  # (batch_pos,)\n",
        "        neg_max = torch.max(neg_scores, dim=1)[0]  # (batch_neg,)\n",
        "\n",
        "        # Hinge loss (ranking loss)\n",
        "        ranking_loss = torch.clamp(\n",
        "            1.0 - pos_max.mean() + neg_max.mean(),\n",
        "            min=0\n",
        "        )\n",
        "\n",
        "        # Temporal smoothness: minimize difference between adjacent segments\n",
        "        smoothness_loss = 0\n",
        "        if pos_scores.size(1) > 1:  # if more than 1 segment\n",
        "            temporal_diff = pos_scores[:, 1:] - pos_scores[:, :-1]  # (batch, num_segments-1)\n",
        "            smoothness_loss = torch.sum(temporal_diff ** 2)\n",
        "\n",
        "        # Sparsity: minimize sum of all scores (encourage sparse anomalies)\n",
        "        sparsity_loss = torch.sum(pos_scores)\n",
        "\n",
        "        # L2 Regularization: apply L2 penalty on model parameters\n",
        "        l2_loss = 0\n",
        "        if model is not None:\n",
        "            for param in model.parameters():\n",
        "                l2_loss += torch.sum(param ** 2)\n",
        "\n",
        "        # Total loss: Sum of all components\n",
        "        total_loss = ranking_loss + self.lambda1 * smoothness_loss + self.lambda2 * sparsity_loss + self.lambda3 * l2_loss\n",
        "\n",
        "        # Optionally scale smoothness and sparsity with alpha to control how much they contribute\n",
        "        total_loss += self.alpha * (self.lambda1 * smoothness_loss + self.lambda2 * sparsity_loss)\n",
        "\n",
        "        return total_loss, {\n",
        "            'ranking_loss': ranking_loss.item(),\n",
        "            'smoothness_loss': smoothness_loss.item() if isinstance(smoothness_loss, torch.Tensor) else 0.0,\n",
        "            'sparsity_loss': sparsity_loss.item(),\n",
        "            'l2_loss': l2_loss.item() if isinstance(l2_loss, torch.Tensor) else 0.0\n",
        "        }\n"
      ],
      "metadata": {
        "id": "WWWKIqaDEqcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Learning Rate Scheduling:\n",
        "\n",
        "Before: The learning rate has remained constant throughout training, which could limit the model's ability to adapt as training progresses.\n",
        "\n",
        "After: I added a learning rate scheduler (StepLR) to decay the learning rate by 30% every 10 epochs.\n",
        "\n",
        "Why: A learning rate scheduler helps the model converge more efficiently by lowering the learning rate as training progresses. This enables finer adjustments to the model's weights as it approaches the optimal solution."
      ],
      "metadata": {
        "id": "Xn1Zza0iFe2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from utils.dataset import C3DFeatureDataset, collate_fn\n",
        "from utils.sampler import BalancedBatchSampler\n",
        "\n",
        "def build_model(config, device):\n",
        "    \"\"\"Build model and move to device\"\"\"\n",
        "    model = ImprovedAnomalyDetector(\n",
        "        input_dim=config['model']['input_dim'],\n",
        "        dropout=config['model']['dropout']\n",
        "    )\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "def initialize_weights(model):\n",
        "    \"\"\"Initialize weights using Xavier uniform distribution for Linear layers.\"\"\"\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_uniform_(m.weight)  # Xavier initialization\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)  # Initialize bias to 0\n",
        "\n",
        "def build_optimizer(model, config):\n",
        "    \"\"\"Build optimizer\"\"\"\n",
        "    optimizer_name = config['training']['optimizer'].lower()\n",
        "    lr = config['training']['learning_rate']\n",
        "    weight_decay = config['training']['lambda3']\n",
        "\n",
        "    if optimizer_name == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'adagrad':\n",
        "        optimizer = optim.Adagrad(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'adamw':  # Add support for AdamW\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, loss, save_path):\n",
        "    \"\"\"Save model checkpoint\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss\n",
        "    }\n",
        "    torch.save(checkpoint, save_path)\n",
        "    print(f\"Checkpoint saved to {save_path}\")\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, device, epoch):\n",
        "    \"\"\"Train one epoch with early stopping\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "    epoch_ranking_loss = 0.0\n",
        "    epoch_smoothness_loss = 0.0\n",
        "    epoch_sparsity_loss = 0.0\n",
        "\n",
        "    progress_bar = tqdm(loader, desc=f\"Epoch {epoch}\")\n",
        "\n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        pos_features = batch['pos_features']\n",
        "        neg_features = batch['neg_features']\n",
        "\n",
        "        if pos_features is None or neg_features is None:\n",
        "            continue\n",
        "\n",
        "        pos_features = pos_features.to(device)\n",
        "        neg_features = neg_features.to(device)\n",
        "\n",
        "        # Forward\n",
        "        pos_scores = model(pos_features)\n",
        "        neg_scores = model(neg_features)\n",
        "\n",
        "        # Loss\n",
        "        loss, loss_dict = criterion(pos_scores, neg_scores)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate losses\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_ranking_loss += loss_dict['ranking_loss']\n",
        "        epoch_smoothness_loss += loss_dict['smoothness_loss']\n",
        "        epoch_sparsity_loss += loss_dict['sparsity_loss']\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f\"{loss.item():.4f}\",\n",
        "            'rank': f\"{loss_dict['ranking_loss']:.4f}\"\n",
        "        })\n",
        "\n",
        "    num_batches = len(loader)\n",
        "    avg_loss = epoch_loss / num_batches\n",
        "    avg_ranking = epoch_ranking_loss / num_batches\n",
        "    avg_smoothness = epoch_smoothness_loss / num_batches\n",
        "    avg_sparsity = epoch_sparsity_loss / num_batches\n",
        "\n",
        "    return {\n",
        "        'loss': avg_loss,\n",
        "        'ranking_loss': avg_ranking,\n",
        "        'smoothness_loss': avg_smoothness,\n",
        "        'sparsity_loss': avg_sparsity\n",
        "    }\n",
        "\n",
        "\n",
        "def main(config):\n",
        "    # Setup device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    checkpoint_dir = Path('checkpoints/New Model')\n",
        "    checkpoint_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Build dataset\n",
        "    train_dataset = C3DFeatureDataset(\n",
        "        annotation_path=config['data']['train_annotation_path'],\n",
        "        features_root=config['data']['feature_path']\n",
        "    )\n",
        "    print(f\"Train dataset: {len(train_dataset)} videos\")\n",
        "\n",
        "    # Build sampler and loader\n",
        "    sampler = BalancedBatchSampler(\n",
        "        train_dataset,\n",
        "        batch_size=config['training']['batch_size']\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_sampler=sampler,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=4\n",
        "    )\n",
        "    print(f\"Total batches per epoch: {len(train_loader)}\")\n",
        "\n",
        "    # Build model\n",
        "    model = build_model(config, device)\n",
        "    initialize_weights(model)  # Apply custom weight initialization\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Build optimizer\n",
        "    optimizer = build_optimizer(model, config)\n",
        "    print(f\"Optimizer: {config['training']['optimizer']}\")\n",
        "\n",
        "    # Build loss\n",
        "    criterion = ImprovedMILRankingLoss(\n",
        "        lambda1=config['training']['lambda1'],\n",
        "        lambda2=config['training']['lambda2']\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=0)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = config['training']['num_epochs']\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        metrics = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "        print(f\"  Loss: {metrics['loss']:.4f}\")\n",
        "        print(f\"  Ranking: {metrics['ranking_loss']:.4f}\")\n",
        "        print(f\"  Smoothness: {metrics['smoothness_loss']:.4f}\")\n",
        "        print(f\"  Sparsity: {metrics['sparsity_loss']:.4f}\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        if epoch % 10 == 0 or metrics['loss'] < best_loss:\n",
        "            save_path = checkpoint_dir / f'epoch_{epoch}.pth'\n",
        "            save_checkpoint(model, optimizer, epoch, metrics['loss'], save_path)\n",
        "            print(f\"  Saved checkpoint: {save_path}\")\n",
        "\n",
        "            if metrics['loss'] < best_loss:\n",
        "                best_loss = metrics['loss']\n",
        "                best_path = checkpoint_dir / 'best_model.pth'\n",
        "                save_checkpoint(model, optimizer, epoch, metrics['loss'], best_path)\n",
        "                print(f\"  New best model: {best_path}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    print(\"\\nTraining completed!\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    config = {\n",
        "        'model': {'input_dim': 4096, 'dropout': 0.5},\n",
        "        'training': {'optimizer': 'adamw', 'learning_rate': 1e-4, 'lambda3': 0.01, 'num_epochs': 100, 'batch_size': 32, 'lambda1': 0.00008, 'lambda2': 0.00008},\n",
        "        'data': {'train_annotation_path': \"data/annotations/train_set.txt\", 'feature_path': \"data/features/\", \"test_annotation_path\": \"data/annotations/test_set.txt\"}\n",
        "    }\n",
        "    main(config)\n"
      ],
      "metadata": {
        "id": "8zZeCoN1CN4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Precision-Recall Curve:\n",
        "\n",
        "Before: Precision-Recall (PR) curve not have been included.\n",
        "\n",
        "After: I added the plot_pr_curve function to calculate and save the PR curve and its AUC for further evaluation.\n",
        "\n",
        "Why: The PR curve is especially useful in imbalanced datasets like anomaly detection, where the number of normal segments greatly outweighs anomalies. The PR AUC gives a better sense of model performance in these cases."
      ],
      "metadata": {
        "id": "QWooekW6FXHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from models.anomaly_detector import AnomalyDetector\n",
        "from utils.dataset import C3DFeatureDataset\n",
        "\n",
        "def load_temporal_annotations(annotation_file):\n",
        "    \"\"\"Load temporal annotations for test videos.\"\"\"\n",
        "    annotations = {}\n",
        "\n",
        "    with open(annotation_file, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 6:\n",
        "                continue\n",
        "\n",
        "            video_name = parts[0].replace('.mp4', '')  # Remove extension\n",
        "            start1, end1 = int(parts[2]), int(parts[3])\n",
        "            start2, end2 = int(parts[4]), int(parts[5])\n",
        "\n",
        "            segments = []\n",
        "            if start1 != -1 and end1 != -1:\n",
        "                segments.append((start1, end1))\n",
        "            if start2 != -1 and end2 != -1:\n",
        "                segments.append((start2, end2))\n",
        "\n",
        "            annotations[video_name] = segments\n",
        "\n",
        "    return annotations\n",
        "\n",
        "\n",
        "def get_frame_level_labels(video_name, annotations, num_segments=32, fps=30):\n",
        "    \"\"\"Generate binary labels for video segments (0 = normal, 1 = anomaly).\"\"\"\n",
        "    labels = np.zeros(num_segments, dtype=np.int32)\n",
        "\n",
        "    base_name = video_name.split('/')[-1]\n",
        "\n",
        "    if base_name not in annotations:\n",
        "        return labels\n",
        "\n",
        "    anomaly_segments = annotations[base_name]\n",
        "\n",
        "    if not anomaly_segments:\n",
        "        return labels\n",
        "\n",
        "    max_frame = max(end for _, end in anomaly_segments)\n",
        "\n",
        "    frames_per_segment = max_frame / num_segments\n",
        "\n",
        "    for seg_idx in range(num_segments):\n",
        "        seg_start = seg_idx * frames_per_segment\n",
        "        seg_end = (seg_idx + 1) * frames_per_segment\n",
        "\n",
        "        for anomaly_start, anomaly_end in anomaly_segments:\n",
        "            if not (seg_end < anomaly_start or seg_start > anomaly_end):\n",
        "                labels[seg_idx] = 1\n",
        "                break\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataset, annotations, device):\n",
        "    \"\"\"Evaluate model on test set.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in tqdm(range(len(dataset)), desc=\"Evaluating\"):\n",
        "            sample = dataset[idx]\n",
        "            features = sample['features'].unsqueeze(0).to(device)  # (1, 32, 4096)\n",
        "            video_name = sample['video_name']\n",
        "\n",
        "            scores = model(features).squeeze(0).cpu().numpy()  # (32,)\n",
        "            labels = get_frame_level_labels(video_name, annotations)\n",
        "\n",
        "            all_labels.extend(labels)\n",
        "            all_scores.extend(scores)\n",
        "\n",
        "    return np.array(all_labels), np.array(all_scores)\n",
        "\n",
        "\n",
        "def plot_roc_curve(labels, scores, save_path):\n",
        "    \"\"\"Plot and save ROC curve\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "             label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"ROC curve saved to {save_path}\")\n",
        "\n",
        "    return roc_auc, fpr, tpr, thresholds\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "def plot_pr_curve(labels, scores, save_path):\n",
        "    \"\"\"Plot and save Precision-Recall curve\"\"\"\n",
        "    precision, recall, _ = precision_recall_curve(labels, scores)\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (AUC = {pr_auc:.4f})')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"PR curve saved to {save_path}\")\n",
        "\n",
        "    return pr_auc\n",
        "\n",
        "\n",
        "def save_results(labels, scores, save_path):\n",
        "    \"\"\"Save evaluation results\"\"\"\n",
        "    results = {\n",
        "        'labels': labels.tolist(),\n",
        "        'scores': scores.tolist()\n",
        "    }\n",
        "\n",
        "    import json\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(results, f)\n",
        "\n",
        "    print(f\"Results saved to {save_path}\")\n",
        "\n",
        "\n",
        "def main(config_file, checkpoint_file, temporal_annotation_file):\n",
        "    config = config_file\n",
        "\n",
        "    # Setup device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load model\n",
        "    model = ImprovedAnomalyDetector(\n",
        "        input_dim=config['model']['input_dim'],\n",
        "        dropout=config['model']['dropout']\n",
        "    )\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(f\"Loaded model from {checkpoint_file}\")\n",
        "    print(f\"Epoch: {checkpoint['epoch']}, Loss: {checkpoint['loss']:.4f}\")\n",
        "\n",
        "    # Load test dataset\n",
        "    test_dataset = C3DFeatureDataset(\n",
        "        annotation_path=config['data']['test_annotation_path'],\n",
        "        features_root=config['data']['feature_path']\n",
        "    )\n",
        "\n",
        "    print(f\"Test dataset: {len(test_dataset)} videos\")\n",
        "\n",
        "    # Load temporal annotations\n",
        "    annotations = load_temporal_annotations(temporal_annotation_file)\n",
        "    print(f\"Loaded temporal annotations for {len(annotations)} videos\")\n",
        "\n",
        "    # Evaluate\n",
        "    print(\"\\nEvaluating new model...\")\n",
        "    new_labels, new_scores = evaluate_model(model, test_dataset, annotations, device)\n",
        "\n",
        "    print(f\"\\nTotal segments evaluated: {len(new_labels)}\")\n",
        "    print(f\"Anomaly segments: {new_labels.sum()} ({new_labels.sum()/len(new_labels)*100:.1f}%)\")\n",
        "    print(f\"Normal segments: {len(new_labels) - new_labels.sum()} ({(len(new_labels)-new_labels.sum())/len(new_labels)*100:.1f}%)\")\n",
        "\n",
        "    # Calculate ROC-AUC\n",
        "    print(\"\\nCalculating ROC curve...\")\n",
        "    results_dir = Path('results/New Model')\n",
        "    results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    roc_auc, fpr, tpr, thresholds = plot_roc_curve(\n",
        "        new_labels, new_scores,\n",
        "        save_path=results_dir / 'roc_curve.png'\n",
        "    )\n",
        "\n",
        "    # Plot and save PR curve\n",
        "    pr_auc = plot_pr_curve(\n",
        "        new_labels, new_scores,\n",
        "        save_path=results_dir / 'pr_curve.png'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"AUC: {roc_auc:.4f}\")\n",
        "    print(f\"PR AUC: {pr_auc:.4f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Save results\n",
        "    save_results(new_labels, new_scores, results_dir / 'evaluation_results.json')\n",
        "\n",
        "    # Find optimal threshold (Youden's J statistic)\n",
        "    j_scores = tpr - fpr\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "    print(f\"\\nOptimal threshold: {optimal_threshold:.4f}\")\n",
        "    print(f\"  TPR: {tpr[optimal_idx]:.4f}\")\n",
        "    print(f\"  FPR: {fpr[optimal_idx]:.4f}\")\n",
        "\n",
        "    # Save summary\n",
        "    summary_path = results_dir / 'evaluation_summary.txt'\n",
        "    with open(summary_path, 'w') as f:\n",
        "        f.write(f\"Evaluation Summary\\n\")\n",
        "        f.write(f\"{'='*60}\\n\")\n",
        "        f.write(f\"Model: {checkpoint_file}\\n\")\n",
        "        f.write(f\"Test videos: {len(test_dataset)}\\n\")\n",
        "        f.write(f\"Total segments: {len(new_labels)}\\n\")\n",
        "        f.write(f\"Anomaly segments: {new_labels.sum()} ({new_labels.sum()/len(new_labels)*100:.1f}%)\\n\")\n",
        "        f.write(f\"\\nResults:\\n\")\n",
        "        f.write(f\"  AUC: {roc_auc:.4f}\\n\")\n",
        "        f.write(f\"  PR AUC: {pr_auc:.4f}\\n\")\n",
        "        f.write(f\"  Optimal threshold: {optimal_threshold:.4f}\\n\")\n",
        "        f.write(f\"  TPR at optimal: {tpr[optimal_idx]:.4f}\\n\")\n",
        "        f.write(f\"  FPR at optimal: {fpr[optimal_idx]:.4f}\\n\")\n",
        "\n",
        "    print(f\"\\nSummary saved to {summary_path}\")\n",
        "\n",
        "\n",
        "# Now, instead of using argparse, call the main function directly\n",
        "config = {\n",
        "    'model': {'input_dim': 4096, 'dropout': 0.5},\n",
        "    'training': {'optimizer': 'adamw', 'learning_rate': 1e-4, 'lambda3': 0.01, 'num_epochs': 100, 'batch_size': 32, 'lambda1': 0.00008, 'lambda2': 0.00008},\n",
        "    'data': {'train_annotation_path': \"data/annotations/train_set.txt\", 'feature_path': \"data/features/\", \"test_annotation_path\": \"data/annotations/test_set.txt\"}\n",
        "}\n",
        "\n",
        "checkpoint_file = '/content/MILRankingLoss_Sultani2018_ReImplementation/checkpoints/New Model/best_model.pth'  # Replace with your path\n",
        "temporal_annotation_file = 'data/annotations/Temporal_Anomaly_Annotation_for_Testing_Videos.txt'  # Replace with your path\n",
        "\n",
        "main(config, checkpoint_file, temporal_annotation_file)\n"
      ],
      "metadata": {
        "id": "GpzSWXqDE3tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MILRankingLoss_Sultani2018_ReImplementation\n",
        "\n",
        "# Display ROC curve\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "if os.path.exists('results/roc_curve.png'):\n",
        "    display(Image('results/roc_curve.png'))\n",
        "\n",
        "\n",
        "if os.path.exists('results/pr_curve.png'):\n",
        "    display(Image('results/pr_curve.png'))\n",
        "\n",
        "if os.path.exists('results/New Model/roc_curve.png'):\n",
        "    display(Image('results/New Model/roc_curve.png'))\n",
        "\n",
        "\n",
        "if os.path.exists('results/New Model/pr_curve.png'):\n",
        "    display(Image('results/New Model/pr_curve.png'))\n",
        "\n",
        "# Print evaluation results\n",
        "if os.path.exists('results/New Model/evaluation_summary.txt'):\n",
        "    !cat results/evaluation_summary.txt"
      ],
      "metadata": {
        "id": "TM8BinD3JF0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backup checkpoints and results to Drive\n",
        "DRIVE_DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/data_distribution/New Model'\n",
        "!mkdir -p \"{DRIVE_DATA_PATH}/results\"\n",
        "!cp -r checkpoints \"{DRIVE_DATA_PATH}/\"\n",
        "!cp -r results \"{DRIVE_DATA_PATH}/\"\n",
        "\n",
        "print(\"Results saved to Google Drive\")"
      ],
      "metadata": {
        "id": "KD6UXChrIVIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}